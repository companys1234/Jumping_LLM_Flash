# Jumping-LLM-Flash
Jumping-LLM-Flash - библиотека для быстрой сборки маленьких языковых моделей, с фокусом на оптимизацию обучения, инференса, и работы с данными.
А также на уменьшение количества кода для построения полного пайплайна. 

# Установка
```bash
git https://github.com/companys1234/Jumping_LLM_Flash.git
```
# Тестовые примеры
LLaMa 2


<a href="https://colab.research.google.com/drive/1J0AtBk9unn7vXKNoF5-NixcIFuWXK5Pw?usp=sharing">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
</a>
