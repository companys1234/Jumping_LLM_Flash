# -*- coding: utf-8 -*-
"""ROPE tests

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GhXaoB3tdS7fFqDSOGRJkJKCo7Fr74if
"""

import torch

def test_rope_output_shape():
    """Тест на правильность формы выходного тензора"""
    batch_size, seq_len, dim = 2, 10, 64
    x = torch.randn(batch_size, seq_len, dim)
    result = rope(x)

    assert result.shape == (batch_size, seq_len, dim), \
        f"Ожидалась форма {(batch_size, seq_len, dim)}, получено {result.shape}"

    batch_size, seq_len, dim = 4, 20, 128
    x = torch.randn(batch_size, seq_len, dim)
    result = rope(x)
    assert result.shape == (batch_size, seq_len, dim)

    print('test passed')

def test_rope_device_preservation():
    """Тест на сохранение устройства тензора"""
    if torch.cuda.is_available():
        # Тест на CPU
        x_cpu = torch.randn(2, 10, 64)
        result_cpu = rope(x_cpu)
        assert result_cpu.device == torch.device('cpu')

        # Тест на GPU
        x_gpu = torch.randn(2, 10, 64).cuda()
        result_gpu = rope(x_gpu)
        assert result_gpu.device == torch.device('cuda', 0)


def test_rope_dtype_preservation():
    """Тест на сохранение типа данных"""
    # Для float32
    x_float32 = torch.randn(2, 10, 64, dtype=torch.float32)
    result_float32 = rope(x_float32)
    assert result_float32.dtype == torch.float32

    # Для float64
    x_float64 = torch.randn(2, 10, 64, dtype=torch.float64)
    result_float64 = rope(x_float64)
    assert result_float64.dtype == torch.float64


def test_rope_identity_for_zero_positions():
    """Тест, что для первого токена вращение минимально"""
    batch_size, seq_len, dim = 1, 1, 64
    x = torch.randn(batch_size, seq_len, dim)
    result = rope(x)


    torch.testing.assert_close(result, x, rtol=1e-5, atol=1e-5)


def test_rope_periodicity_property():
    """Тест периодичности RoPE (примерное сохранение нормы)"""
    torch.manual_seed(42)
    batch_size, seq_len, dim = 2, 10, 64
    x = torch.randn(batch_size, seq_len, dim)
    result = rope(x)

    # Норма должна сохраняться (приблизительно)
    original_norms = torch.norm(x, dim=-1)
    result_norms = torch.norm(result, dim=-1)

    torch.testing.assert_close(original_norms, result_norms, rtol=1e-5, atol=1e-5)


def test_rope_reversibility():
    """Тест на возможность обратного преобразования (при определённых условиях)"""
    torch.manual_seed(42)
    batch_size, seq_len, dim = 2, 5, 64
    x = torch.randn(batch_size, seq_len, dim)


    x_rope = rope(x)


    x_rev = x.flip(1)  # обратный порядок последовательности


    x_rev_rope = rope(x_rev)


    x_rev_rope_rev = x_rev_rope.flip(1)

    # Это не должно быть равно исходному x_rope, но должно иметь ту же норму
    assert not torch.allclose(x_rope, x_rev_rope_rev, rtol=1e-5)
    assert torch.allclose(torch.norm(x_rope, dim=-1),
                         torch.norm(x_rev_rope_rev, dim=-1),
                         rtol=1e-5)


def test_rope_gradients():
    """Тест на наличие градиентов"""
    batch_size, seq_len, dim = 2, 10, 64
    x = torch.randn(batch_size, seq_len, dim, requires_grad=True)

    result = rope(x)
    loss = result.sum()
    loss.backward()

    assert x.grad is not None
    assert not torch.allclose(x.grad, torch.zeros_like(x.grad))